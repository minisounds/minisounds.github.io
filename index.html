<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jason Zhang</title>
    <link rel="stylesheet" href="main.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ§ </text></svg>">
</head>
<body>
    <nav>
        <div class="nav-left"><a href="blog.html">Blog</a></div>
        <div class="nav-center">Jason Zhang</div>
        <div class="nav-right">
            <a href="https://x.com/minisounds" aria-label="Twitter"><img class="nav-icon" src="media/twitter.png" alt="Twitter Logo"></a>
            <a href="https://scholar.google.com/citations?user=LY1rce8AAAAJ&hl=en&authuser=1" aria-label="GitHub"><img class="nav-icon" src="media/googlescholar.svg" alt="GitHub Logo"></a>
            <a href="https://www.linkedin.com/in/jason-zhang-6860361b8/" aria-label="LinkedIn"><img class="nav-icon" src="media/linkedin.png" alt="LinkedIn Logo"></a>
        </div>
    </nav>

    <main class="container">
        <section class="profile-section">
            <div class="profile-image">
                <img src="media/pfp.jpg" alt="Your professional photo">
            </div>
            <div class="profile-content">
                <h1>Jason Zhang</h1>
                <div class="location">Stanford, CA, US</div>
                <p>
                    Hi! I'm Jason, a student at Stanford and a researcher at <a href="https://lambda.ai/research" target="_blank">Lambda</a> & <a href="https://ai.stanford.edu/" target="_blank">Stanford AI Lab</a>. 
                    I'm fascinated by how our brains seamlessly integrate vision, language, and sensory experience into unified understanding. I'm currently researching techniques and architectures for multimodal reasoning inspired by these principles. 
                    On the side, I lead the Speaker Series & serve as Co-President for the <a href="https://stanfordaiclub.vercel.app/" target="_blank">Stanford AI Club</a>!
                </p>
            </div>
        </section>

        <section class="featured-projects">
            <h2>Featured Projects</h2>
            
            <div class="project-card">
                <div class="project-image">
                    <img src="media/cot2.png" alt="CoT Vectors project visualization">
                </div>
                <div class="project-content">
                    <h3>Uncovering Latent CoT Vectors in Language Models <span class="conference-tag">[ICLR-W 2025]</span></h3>
                    <p>Applied Steering Vectors towards Chain of Thought Thinking. Show that steered systems can be steered towards CoT structure
                        while maintaining competitive performance on reasoning benchmarks. Read <a href="https://arxiv.org/abs/2409.14026" target="_blank"> here</a>! 
                    </p>
                </div>
            </div>

            <div class="project-card">
                <div class="project-image">
                    <img src="media/spice.gif" alt="Text-to-video generation project visualization">
                </div>
                <div class="project-content">
                    <h3>Improving Controllability of Text-to-Video Generation Through Image Editing and Interpolation</h3>
                    <p>Built a modular text-to-video editing pipeline for Stanford's <a href="https://stanford-cs131.github.io/winter2025/" target="_blank">CS131 Class</a> using iterative keyframe editing and frame interpolation. Achieved near SoTA on VBench against models like Luma and Sora while also enabling intuitive editing. Check it out <a href="./media/spice_paper.pdf" target="_blank">here</a>!
                    </p>
                </div>
            </div>
            
            <div class="project-card">
                <div class="project-image">
                    <img src="media/seri.png" alt="Structural safety generalization project visualization">
                </div>
                <div class="project-content">
                    <h3>The Structural Safety Generalization Problem <span class="conference-tag">[ACL Findings 2025]</span></h3>
                    <p>Introduce new subclass of AI Safety problems - failure of current safety techniques to generalize over structure, despite semantic equivalence. 
                        Read <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=LY1rce8AAAAJ&authuser=1&citation_for_view=LY1rce8AAAAJ:d1gkVwhDpl0C" target="_blank">here</a>. 
                    </p>
                </div>
            </div>

            <div class="project-card">
                <div class="project-image">
                    <img src="media/saes.png" alt="Sparse autoencoders feature geometry project visualization">
                </div>
                <div class="project-content">
                    <h3>Empirical Insights into Feature Geometry in Sparse Autoencoders<span class="conference-tag"> (LessWrong)</span></h3>
                    <p> Interpretability Research with Sparse Autoencoders (SAEs) conducted under Zhengxuan Wu in Chris Pott's Lab. present the first demonstration of the lack of geometric relationships
                        between semantically related concepts in the Feature Space of SAEs. 
                        Read <a href="https://www.lesswrong.com/posts/rZmJwv4mSNeyeEu3g/empirical-insights-into-feature-geometry-in-sparse" target="_blank">here</a>. 
                    </p>
                </div>
            </div>
        
        </section>

        <section class="writing">
            <h2>Writing</h2>

            <div class="blog-post-card">
                <h3>
                    <a href="blog_posts/ai_intuition.html">How to Build Intuition in AI</a>
                </h3>
                <p class="post-date">December 11, 2025</p>
                <p>
                    Having strong intuition and "feel" on ML concepts is a non-negotiable prerequisite for being productive in ML research.
                    But how do you build it? In this post I share 3 pitfalls I've made in my journey, as well as the current 3-step framework
                    I've arrived at that I find to be most effective (and fun!) for building a robust, practical intuition in AI/ML.
                </p>
            </div>

            <div class="blog-post-card">
                <h3>
                    <a href="blog_posts/benchmarks.html">Building Better Benchmarks: We Need Standardized AI Evaluation</a>
                </h3>
                <p class="post-date">December 11, 2024</p>
                <p>
                    AI benchmarking is in a state of disarray. From data leakage to reproducibility issues, our current evaluation methods raise serious questions about how we measure AI capabilities. This post explores the limitations of today's benchmarks and proposes a unified set of best practices for moving forward.
                </p>
            </div>
        </section>

        <section class="social-links">
            <a href="https://scholar.google.com/citations?user=LY1rce8AAAAJ&hl=en&authuser=1" target="_blank">Google Scholar</a>
            <a href="https://x.com/minisounds" target="_blank">Twitter</a>
            <a href="https://github.com/minisounds" target="_blank">GitHub</a>
            <a href="https://www.linkedin.com/in/jason-zhang-6860361b8/" target="_blank">LinkedIn</a>
            <a href="mailto:jasonbz@stanford.edu" target="_blank">Email</a>
        </section>
    </main>
</body>
</html>
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blog - Jason Zhang</title>
    <link rel="stylesheet" href="main.css">
</head>
<body>
    <nav>
        <div class="nav-left">
            <a href="index.html">Home</a>
        </div>
        
        <div class="nav-center">
            <a href="index.html">Jason Zhang</a>
        </div>
        
        <div class="nav-right">
            <a href="https://x.com/minisounds" aria-label="Twitter">
                <img src="media/twitter.png" alt="Twitter Logo" class="nav-icon">
            </a>
            <a href="https://scholar.google.com/citations?user=LY1rce8AAAAJ&hl=en&authuser=1" aria-label="GitHub">
                <img src="media/googlescholar.svg" alt="GitHub Logo" class="nav-icon">
            </a>
            <a href="https://www.linkedin.com/in/jason-zhang-6860361b8/" aria-label="LinkedIn">
                <img src="media/linkedin.png" alt="LinkedIn Logo" class="nav-icon">
            </a>
        </div>
    </nav>

    <main class="container">
            <div class="blog-posts">
            <h1>Blog Posts</h1>

            <div class="blog-post-card">
                <h3>
                    <a href="blog_posts/ai_intuition.html">How I Approach Building Intuition in AI/ML Research</a>
                </h3>
                <p class="post-date">December 11, 2025</p>
                <p>
                    Building strong intuition in AI/ML research is crucial but challenging. As an undergrad who's invested 100+ hours exploring this field, I've learned that traditional approaches like jumping straight into papers or lengthy courses often fail to build the foundation needed. This post introduces a practical 3-step framework using LLMs to develop genuine understanding quickly and effectively.
                </p>
            </div>

            <div class="blog-post-card">
                <h3>
                    <a href="blog_posts/benchmarks.html">Building Better Benchmarks: We Need Standardized AI Evaluation</a>
                </h3>
                <p class="post-date">December 11, 2024</p>
                <p>
                    AI benchmarking is in a state of disarray. From data leakage to reproducibility issues, our current evaluation methods raise serious questions about how we measure AI capabilities. This post explores the limitations of today's benchmarks and proposes a unified set of best practices for moving forward.
                </p>
            </div>
        </div>
    </main>
</body>
</html>
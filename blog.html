<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Blog - Jason Zhang</title>
    <link rel="stylesheet" href="main.css">
</head>
<body>
    <nav>
        <div class="nav-left">
            <a href="index.html">Home</a>
        </div>
        
        <div class="nav-center">
            <a href="index.html">Jason Zhang</a>
        </div>
        
        <div class="nav-right">
            <a href="https://x.com/minisounds" aria-label="Twitter">
                <img src="media/twitter.png" alt="Twitter Logo" class="nav-icon">
            </a>
            <a href="https://scholar.google.com/citations?user=LY1rce8AAAAJ&hl=en&authuser=1" aria-label="GitHub">
                <img src="media/googlescholar.svg" alt="GitHub Logo" class="nav-icon">
            </a>
            <a href="https://www.linkedin.com/in/jason-zhang-6860361b8/" aria-label="LinkedIn">
                <img src="media/linkedin.png" alt="LinkedIn Logo" class="nav-icon">
            </a>
        </div>
    </nav>

    <main class="container">
            <div class="blog-posts">
            <h1>Writing</h1>

            <div class="blog-post-card">
                <h3>
                    <a href="blog_posts/ai_intuition.html">How to Build Intuition in AI</a>
                </h3>
                <p class="post-date">December 11, 2025</p>
                <p>
                    Having strong intuition and “feel” on ML concepts is a non-negotiable prerequisite for being productive in ML research.
                    But how do you build it? In this post I share 3 pitfalls I've made in my journey, as well as the current 3-step framework 
                    I've arrived at that I find to be most effective (and fun!) for building a robust, practical intuition in AI/ML. 
                </p>
            </div>

            <div class="blog-post-card">
                <h3>
                    <a href="blog_posts/benchmarks.html">Building Better Benchmarks: We Need Standardized AI Evaluation</a>
                </h3>
                <p class="post-date">December 11, 2024</p>
                <p>
                    AI benchmarking is in a state of disarray. From data leakage to reproducibility issues, our current evaluation methods raise serious questions about how we measure AI capabilities. This post explores the limitations of today's benchmarks and proposes a unified set of best practices for moving forward.
                </p>
            </div>
        </div>
    </main>
</body>
</html>
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>On Building Intuition in AI/ML</title>
    <link rel="stylesheet" href="../main.css">
</head>
<body>
    <nav>
        <div class="nav-left">
            <a href="../blog.html">← Blog</a>
        </div>

        <div class="nav-center">
            <a href="../index.html">Jason Zhang</a>
        </div>

        <div class="nav-right">
            <a href="https://x.com/minisounds" aria-label="Twitter">
                <img src="../media/twitter.png" alt="Twitter Logo" class="nav-icon">
            </a>
            <a href="https://scholar.google.com/citations?user=LY1rce8AAAAJ&hl=en&authuser=1" aria-label="GitHub">
                <img src="../media/googlescholar.svg" alt="GitHub Logo" class="nav-icon">
            </a>
            <a href="https://www.linkedin.com/in/jason-zhang-6860361b8/" aria-label="LinkedIn">
                <img src="../media/linkedin.png" alt="LinkedIn Logo" class="nav-icon">
            </a>
        </div>
    </nav>

    <main class="container">
        <article class="blog-post">
            <figure class="post-banner">
                <img src="../media/blog/ai_intuition/title1.JPG" alt="On Building Intuition in AI/ML">
            </figure>

            <h1>How to Build Intuition in AI</h1>
            <div class="post-metadata">
                Jason Zhang <br>
                December 11, 2025
            </div>

            <p class="quote">
                "It is by logic that we prove, but by intuition that we discover." - Henri Poincaré
            </p>
            <p>
                Having strong intuition and “feel” on ML concepts (architectures, training techniques, etc.) is a non-negotiable prerequisite for being productive in ML research. But how do you build it? 

                <br><br>
                
                The answer isn't as simple as it may seem, and from my experience, I don't think people talk about how to do this efficiently. 
                As an undergrad who's sunken probably over 200 hours into this and made many mistakes along the way, I wanted to share 3 pitfalls I've made in my journey, 
                as well as the current 3-step framework I've arrived at that I find to be most effective (and fun!) for building a robust, practical intuition in AI/ML efficiently. 
            </p>

            <h2>What NOT to Do When Learning AI/ML Concepts</h2>

            <h3>1. Don't Go Straight to the Papers</h3>
            <p>
                Papers, especially frontier ones, assume strong intuition and feel for a topic to be properly understood and appreciated. Treating these as an introductory resource for understanding a concept sets you up for failure. Seems simple, but I know I've made this mistake several times and have wasted countless hours trying to understand papers I simply didn't have the foundations to fully understand.
            </p>

            <h3>2. Don't Go to the Survey Papers, Either</h3>
            <p>
                While a step in the right direction from reading frontier papers, in my experience, frontier papers still assume some level of prior knowledge (whether it's math, theory, etc). They also frequently use technical jargon, whether in the form of algorithms or derivations, introducing these concepts frequently before one is ready to appreciate them.
            </p>

            <h3>3. Online Courses/Lecture Series Are Inefficient</h3>
            <p>
                You might learn the information deeply, but completing a course frequently takes tens of hours to complete and a significant amount of energy. If you're in general a pretty busy person (student/working job), online courses take too long and are inconvenient.
            </p>

            <h2>My 3-Step Framework for Building Intuition</h2>
            <p>
                What we want for building intuition is something that can be done quickly (&lt; 30 min), be completely tailored to your current understanding, and builds a robust and practical foundation for you to then apply however you'd like (reading papers, implementing papers, etc). Obviously, we will use LLMs to do this. But exactly how to do this efficiently is less clear. After sinking probably 100+ hours into experimenting with this, here's the framework I've arrived at that I find to be most effective (and fun!)
            </p>

            <h3>Step 0: Create a Project</h3>
            <p>
                Create a project (on GPT/Claude) and title it the concept you want to learn (e.g. "Variational Inference" or "Transformers"). This allows you to both organize your understanding neatly but also to enable project-local memory (in case one chat gets too long, Claude/ChatGPT will remember it for you in future conversations).
            </p>

            <h3>Step 1: Build High Level Intuition</h3>
            <p>
                Your first goal is to gain a high level intuition of the concept. Throw out all math, logic, and technical jargon out of the window. Ask the model to explain a concept to you like you're twelve. Here's a prompt I like to use with some prompting tricks I've found useful highlighted:
            </p>
            <img src="../media/blog/ai_intuition/prompt1.png" alt="Example prompt for building high-level intuition" class="blog-content-image">

            <h3>Step 2: Rapidly Identify Holes in Your Intuition and Fill Them</h3>
            <p>
                Ask any follow-up questions you have. Then, once you feel like you've gotten a basic grasp, try re-explaining the concept back to the LLM from scratch. Ask the LLM to identify any inaccuracies in your explanation or key missing pieces of the intuition that you missed. You might also find that in re-explaining this concept, a series of new follow up questions might come up. Save these and maybe even ask them first before resuming your explanation of the concept.
            </p>
            <img src="../media/blog/ai_intuition/prompt2.png" alt="Example prompt for identifying holes in intuition" class="blog-content-image">

            <h3>Step 3: Make Learning Multimodal</h3>
            <p>
                After going through the Feynman loop a couple of times (explaining the concept, realizing what parts of the concept you don't understand, then explaining again), it's time to go one step further by making your learning multimodal. Ask the model to implement the concept in annotated, interpretable code. Or ask it to introduce you to the core mathematical derivations / formulas. Doing this has helped me bridge the gap between high level concept and practical, working level understanding that makes my understanding of the concept even more robust.
            </p>
            <img src="../media/blog/ai_intuition/prompt3.png" alt="Example prompt for making learning multimodal" class="blog-content-image">

            <h2>Now You're Ready to Move Forward</h2>
            <p>
                That's it! Now you are ready to move forward as you please: read the frontier papers (they should now seem 10x less intimidating and 10x more insightful!), implement the concept/papers yourself from scratch, or start thinking about research tests you'd be curious to run given any ideas that popped up into your head.
            </p>
        </article>
    </main>

</body>
</html>
